{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3af6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68aa8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ddc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[0:10,:]\n",
    "y=data.iloc[400:410,:]\n",
    "test_data=pd.DataFrame()\n",
    "train_data=pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb1642c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.101760</td>\n",
       "      <td>0.095119</td>\n",
       "      <td>0.022390</td>\n",
       "      <td>0.033455</td>\n",
       "      <td>-0.028316</td>\n",
       "      <td>-0.071314</td>\n",
       "      <td>-0.076263</td>\n",
       "      <td>-0.173371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103842</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>-0.038534</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>-0.195098</td>\n",
       "      <td>-0.065993</td>\n",
       "      <td>0.086835</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>0.134832</td>\n",
       "      <td>0.053776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.126957</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>-0.062769</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>-0.069378</td>\n",
       "      <td>-0.109074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079223</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>-0.158518</td>\n",
       "      <td>-0.084066</td>\n",
       "      <td>-0.004959</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>0.057033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>0.021787</td>\n",
       "      <td>0.047769</td>\n",
       "      <td>0.031156</td>\n",
       "      <td>-0.036925</td>\n",
       "      <td>-0.125392</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>-0.153379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057198</td>\n",
       "      <td>0.043197</td>\n",
       "      <td>-0.046054</td>\n",
       "      <td>0.062767</td>\n",
       "      <td>-0.116895</td>\n",
       "      <td>-0.179019</td>\n",
       "      <td>-0.045612</td>\n",
       "      <td>-0.052743</td>\n",
       "      <td>0.034252</td>\n",
       "      <td>0.046343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.091019</td>\n",
       "      <td>0.042462</td>\n",
       "      <td>-0.061052</td>\n",
       "      <td>-0.070249</td>\n",
       "      <td>-0.050925</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.061084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042027</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.095180</td>\n",
       "      <td>-0.107603</td>\n",
       "      <td>0.031764</td>\n",
       "      <td>-0.026397</td>\n",
       "      <td>0.049204</td>\n",
       "      <td>-0.050450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.082929</td>\n",
       "      <td>0.058382</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>-0.010675</td>\n",
       "      <td>-0.099150</td>\n",
       "      <td>-0.102433</td>\n",
       "      <td>0.037710</td>\n",
       "      <td>-0.125727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037042</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>-0.046081</td>\n",
       "      <td>-0.123925</td>\n",
       "      <td>-0.124878</td>\n",
       "      <td>-0.028671</td>\n",
       "      <td>-0.026378</td>\n",
       "      <td>0.048825</td>\n",
       "      <td>-0.025185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.129449</td>\n",
       "      <td>0.132177</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>-0.009390</td>\n",
       "      <td>-0.080541</td>\n",
       "      <td>-0.072362</td>\n",
       "      <td>-0.067433</td>\n",
       "      <td>-0.192243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142675</td>\n",
       "      <td>0.028204</td>\n",
       "      <td>-0.010465</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.117138</td>\n",
       "      <td>-0.148947</td>\n",
       "      <td>0.054327</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.046730</td>\n",
       "      <td>0.037774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.158460</td>\n",
       "      <td>0.109948</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>-0.069668</td>\n",
       "      <td>0.032311</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>-0.140817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143453</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>0.056758</td>\n",
       "      <td>-0.064352</td>\n",
       "      <td>-0.108518</td>\n",
       "      <td>0.132037</td>\n",
       "      <td>0.050347</td>\n",
       "      <td>0.071465</td>\n",
       "      <td>-0.022954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.101499</td>\n",
       "      <td>0.119739</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>-0.055524</td>\n",
       "      <td>0.028399</td>\n",
       "      <td>0.028164</td>\n",
       "      <td>-0.152100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046488</td>\n",
       "      <td>0.051044</td>\n",
       "      <td>-0.008298</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>-0.164197</td>\n",
       "      <td>-0.122292</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>-0.030194</td>\n",
       "      <td>-0.018642</td>\n",
       "      <td>0.032821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.149516</td>\n",
       "      <td>0.081588</td>\n",
       "      <td>0.090796</td>\n",
       "      <td>-0.053116</td>\n",
       "      <td>-0.133314</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.019941</td>\n",
       "      <td>-0.117803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111678</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>0.059115</td>\n",
       "      <td>-0.007810</td>\n",
       "      <td>-0.096824</td>\n",
       "      <td>-0.079415</td>\n",
       "      <td>-0.015487</td>\n",
       "      <td>-0.075470</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>0.052727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>female</td>\n",
       "      <td>0.039844</td>\n",
       "      <td>0.070357</td>\n",
       "      <td>0.130196</td>\n",
       "      <td>-0.007683</td>\n",
       "      <td>-0.077825</td>\n",
       "      <td>-0.021298</td>\n",
       "      <td>-0.024133</td>\n",
       "      <td>-0.085105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105510</td>\n",
       "      <td>0.081928</td>\n",
       "      <td>-0.033337</td>\n",
       "      <td>-0.023604</td>\n",
       "      <td>-0.167003</td>\n",
       "      <td>-0.059075</td>\n",
       "      <td>0.053074</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>-0.021999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 Unnamed: 1         0         1         2         3         4  \\\n",
       "10           11       male -0.101760  0.095119  0.022390  0.033455 -0.028316   \n",
       "11           12       male -0.126957  0.065444 -0.014750 -0.062769  0.006243   \n",
       "12           13       male  0.021787  0.047769  0.031156 -0.036925 -0.125392   \n",
       "13           14       male -0.091019  0.042462 -0.061052 -0.070249 -0.050925   \n",
       "14           15       male -0.082929  0.058382  0.008007 -0.010675 -0.099150   \n",
       "..          ...        ...       ...       ...       ...       ...       ...   \n",
       "395         396       male -0.129449  0.132177  0.055916 -0.009390 -0.080541   \n",
       "396         397       male -0.158460  0.109948  0.019088  0.015506 -0.069668   \n",
       "397         398       male -0.101499  0.119739  0.016951 -0.013677 -0.055524   \n",
       "398         399       male -0.149516  0.081588  0.090796 -0.053116 -0.133314   \n",
       "399         400     female  0.039844  0.070357  0.130196 -0.007683 -0.077825   \n",
       "\n",
       "            5         6         7  ...       118       119       120  \\\n",
       "10  -0.071314 -0.076263 -0.173371  ...  0.103842  0.064531 -0.038534   \n",
       "11   0.033722 -0.069378 -0.109074  ...  0.079223  0.102630  0.014118   \n",
       "12   0.009113 -0.014069 -0.153379  ...  0.057198  0.043197 -0.046054   \n",
       "13  -0.114522 -0.001090 -0.061084  ...  0.042027 -0.003301  0.002241   \n",
       "14  -0.102433  0.037710 -0.125727  ...  0.037042 -0.006108 -0.022526   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395 -0.072362 -0.067433 -0.192243  ...  0.142675  0.028204 -0.010465   \n",
       "396  0.032311  0.015062 -0.140817  ...  0.143453  0.059608 -0.006824   \n",
       "397  0.028399  0.028164 -0.152100  ...  0.046488  0.051044 -0.008298   \n",
       "398  0.001096  0.019941 -0.117803  ...  0.111678 -0.016921  0.059115   \n",
       "399 -0.021298 -0.024133 -0.085105  ...  0.105510  0.081928 -0.033337   \n",
       "\n",
       "          121       122       123       124       125       126       127  \n",
       "10   0.045669 -0.195098 -0.065993  0.086835  0.045227  0.134832  0.053776  \n",
       "11   0.011191 -0.158518 -0.084066 -0.004959 -0.025286 -0.003429  0.057033  \n",
       "12   0.062767 -0.116895 -0.179019 -0.045612 -0.052743  0.034252  0.046343  \n",
       "13  -0.001005 -0.095180 -0.107603  0.031764 -0.026397  0.049204 -0.050450  \n",
       "14  -0.046081 -0.123925 -0.124878 -0.028671 -0.026378  0.048825 -0.025185  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "395  0.002703 -0.117138 -0.148947  0.054327  0.004200  0.046730  0.037774  \n",
       "396  0.056758 -0.064352 -0.108518  0.132037  0.050347  0.071465 -0.022954  \n",
       "397  0.018010 -0.164197 -0.122292  0.032616 -0.030194 -0.018642  0.032821  \n",
       "398 -0.007810 -0.096824 -0.079415 -0.015487 -0.075470  0.062481  0.052727  \n",
       "399 -0.023604 -0.167003 -0.059075  0.053074  0.080940  0.011467 -0.021999  \n",
       "\n",
       "[390 rows x 130 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.concat([x,y])\n",
    "x=data.iloc[10:400,:]\n",
    "y=data.iloc[410:800,:]\n",
    "train_data=pd.concat([x,y])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7deabaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.06069398e-02  9.28381927e-02  4.38483341e-02 -3.00598442e-02\n",
      " -9.33265559e-02 -1.36620278e-02 -1.06818231e-02 -1.05847883e-01\n",
      "  1.29286480e-01 -5.08604494e-02  1.99346462e-01 -3.32977765e-02\n",
      " -2.40189641e-01 -6.01639225e-02 -1.92338729e-02  1.04881078e-01\n",
      " -1.49160752e-01 -1.12220594e-01 -1.22513783e-01 -9.05441252e-02\n",
      "  1.22015684e-02  2.90742705e-02  3.29343159e-02  4.30212584e-03\n",
      " -1.39532551e-01 -3.08355318e-01 -7.41240195e-02 -9.70094606e-02\n",
      "  6.62154374e-02 -9.69260067e-02  2.06240179e-02  4.02553343e-02\n",
      " -1.82535834e-01 -7.44182753e-02  1.90023221e-02  4.77028485e-02\n",
      " -4.61199703e-02 -5.97181360e-02  2.06901451e-01  2.48548115e-02\n",
      " -1.51949272e-01  2.51998596e-02  4.75094770e-02  2.55579604e-01\n",
      "  1.93501376e-01  6.30462398e-03  2.38075744e-02 -6.04318581e-02\n",
      "  1.17005293e-01 -2.43055885e-01  6.06642988e-02  1.34546141e-01\n",
      "  1.43953700e-01  6.90097574e-02  8.52283540e-02 -1.28424423e-01\n",
      "  1.95907744e-02  1.31655732e-01 -1.88146066e-01  8.84363241e-02\n",
      "  7.91438653e-02 -9.15247583e-02 -4.71580926e-02 -2.69145053e-02\n",
      "  1.48879202e-01  8.85218526e-02 -7.62496625e-02 -1.31343090e-01\n",
      "  1.67569279e-01 -1.30201268e-01 -4.94102782e-02  6.02148115e-02\n",
      " -8.56180587e-02 -1.51668648e-01 -2.71705694e-01  5.18974041e-02\n",
      "  3.62697053e-01  1.26882762e-01 -1.86607672e-01 -1.84131077e-03\n",
      " -7.20475133e-02 -1.21258585e-02  3.85428467e-02  2.64268036e-02\n",
      " -9.14738152e-02 -5.44137247e-02 -8.98672369e-02  2.68803031e-02\n",
      "  1.79127816e-01 -2.03940244e-02 -3.50374343e-02  2.07768703e-01\n",
      "  1.67398151e-02 -3.93186490e-03  5.17129384e-02  3.99079090e-02\n",
      " -1.16908576e-01 -1.47493328e-02 -1.05632093e-01 -1.15097378e-02\n",
      "  6.60708752e-02 -1.17672866e-01  1.40794398e-02  8.67932060e-02\n",
      " -1.74597274e-01  1.62036718e-01 -1.62208688e-02 -3.05937382e-02\n",
      "  1.97342236e-04 -1.48839806e-02 -7.93000738e-02  3.08079373e-03\n",
      "  1.69759780e-01 -2.44900646e-01  2.18008265e-01  1.79938468e-01\n",
      " -3.00297761e-03  1.26526783e-01  6.48331332e-02  5.11918962e-02\n",
      " -2.10601118e-03  6.62407040e-03 -1.25789462e-01 -1.18443998e-01\n",
      "  2.20318346e-02 -2.44961616e-02  1.92592217e-02  3.95592811e-02]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean1=[]\n",
    "for i in range(2,130):\n",
    "    a=str(i)\n",
    "    mean1.append(np.mean(x.iloc[:,i]))\n",
    "\n",
    "mean1=np.array(mean1)\n",
    "print(mean1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d869098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     -0.104053\n",
      "1      0.084807\n",
      "2      0.062869\n",
      "3     -0.053774\n",
      "4     -0.107821\n",
      "         ...   \n",
      "123   -0.102711\n",
      "124    0.037940\n",
      "125   -0.027949\n",
      "126    0.011944\n",
      "127    0.033123\n",
      "Length: 128, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(data.iloc[:, 2:], axis=0)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de4fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('gender.csv')\n",
    "\n",
    "# Extract the features (assuming the features are in columns 2 and onwards)\n",
    "X = dataset.iloc[:, 2:].values\n",
    "\n",
    "# Standardize the data\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = (X - mean) / std\n",
    "\n",
    "# Perform PCA to reduce dimensionality\n",
    "variance_threshold = 0.95\n",
    "pca = PCA(n_components=variance_threshold)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data = np.concatenate([X_reduced[:390], X_reduced[400:790]])\n",
    "test_data = np.concatenate([X_reduced[390:400], X_reduced[790:800]])\n",
    "\n",
    "# Calculate the means for each class in the training data\n",
    "class_0_mean = np.mean(train_data[:390], axis=0)\n",
    "class_1_mean = np.mean(train_data[390:], axis=0)\n",
    "\n",
    "# Classify the test data points\n",
    "predictions = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    dist_0 = np.linalg.norm(test_data[i] - class_0_mean)\n",
    "    dist_1 = np.linalg.norm(test_data[i] - class_1_mean)\n",
    "    \n",
    "    if dist_0 < dist_1:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "\n",
    "# Define the true labels for the test data\n",
    "true_labels = [0] * 10 + [1] * 10\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71bb313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('gender.csv')\n",
    "mean = np.mean(dataset.iloc[:, 2:], axis=0)\n",
    "\n",
    "cov_matrix = dataset.iloc[:, 2:].cov()\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues in descending order\n",
    "indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues_sorted = eigenvalues[indices]\n",
    "eigenvectors_sorted = eigenvectors[:, indices]\n",
    "\n",
    "total_variance = np.sum(eigenvalues_sorted)\n",
    "\n",
    "variance_threshold = 0.95\n",
    "cumulative_variance = np.cumsum(eigenvalues_sorted) / total_variance\n",
    "k = np.argmax(cumulative_variance >= variance_threshold) + 1  # Add 1 because indexing starts from 0\n",
    "\n",
    "selected_eigenvectors = eigenvectors_sorted[:, :k]\n",
    "selected_eigenvalues = eigenvalues_sorted[:k]\n",
    "\n",
    "data_reduced = np.dot(dataset.iloc[:, 2:]-mean, selected_eigenvectors)\n",
    "# data_reduced.shape\n",
    "test = data_reduced[390:400]\n",
    "test = np.concatenate([test, data_reduced[790:800]])\n",
    "\n",
    "train = data_reduced[0:390]\n",
    "train = np.concatenate([train, data_reduced[400:790]])\n",
    "means = [np.mean(train[0:390], axis=0), np.mean(train[390:], axis=0)]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    min_dist = float('inf')\n",
    "    prediction = -1\n",
    "\n",
    "    for j in range(2):\n",
    "        dist = np.linalg.norm(test[i] - means[j])\n",
    "\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            prediction = j\n",
    "\n",
    "    predictions.append(prediction)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if i<10 and predictions[i] == 0:\n",
    "        correct += 1\n",
    "    elif i>10 and predictions[i] == 1:\n",
    "        correct += 1\n",
    "    else:\n",
    "        correct -= 1\n",
    "\n",
    "print('Accuracy : ', correct/test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0845dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from 'gender.csv'\n",
    "dataset = pd.read_csv('gender.csv')\n",
    "X=dataset.iloc[:,2:]\n",
    "\n",
    "# Calculate the mean of the dataset columns from the third column onwards\n",
    "feature_means = np.mean(X, axis=0)\n",
    "\n",
    "# Calculate the covariance matrix of the dataset columns from the third column onwards\n",
    "covariance_matrix = X.cov()\n",
    "\n",
    "# Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# Sort eigenvalues in descending order\n",
    "eigenvalue_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[eigenvalue_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, eigenvalue_indices]\n",
    "\n",
    "# Calculate the total variance\n",
    "total_variance = np.sum(sorted_eigenvalues)\n",
    "\n",
    "# Set a threshold for the cumulative variance to retain\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Calculate cumulative variance and determine the number of principal components to retain\n",
    "cumulative_variance = np.cumsum(sorted_eigenvalues) / total_variance\n",
    "num_components_to_retain = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "\n",
    "# Select the top 'num_components_to_retain' eigenvectors\n",
    "selected_eigenvectors = sorted_eigenvectors[:, :num_components_to_retain]\n",
    "selected_eigenvalues = sorted_eigenvalues[:num_components_to_retain]\n",
    "\n",
    "# Reduce the data using the selected eigenvectors and mean\n",
    "reduced_data = np.dot(dataset.iloc[:, 2:] - feature_means, selected_eigenvectors)\n",
    "\n",
    "# Split the data into test and training sets\n",
    "test_data = np.concatenate([reduced_data[390:400], reduced_data[790:800]])\n",
    "train_data = np.concatenate([reduced_data[0:390], reduced_data[400:790]])\n",
    "\n",
    "# Compute the means for the two classes in the training data\n",
    "class_means = [np.mean(train_data[0:390], axis=0), np.mean(train_data[390:], axis=0)]\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Classify test samples\n",
    "for i in range(test_data.shape[0]):\n",
    "    min_distance = float('inf')\n",
    "    predicted_class = -1\n",
    "\n",
    "    for j in range(2):\n",
    "        distance = np.linalg.norm(test_data[i] - class_means[j])\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            predicted_class = j\n",
    "\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if i < 10 and predictions[i] == 0:\n",
    "        correct += 1\n",
    "    elif i >= 10 and predictions[i] == 1:\n",
    "        correct += 1\n",
    "    else:\n",
    "        correct -= 1\n",
    "\n",
    "accuracy = correct / test_data.shape[0]\n",
    "\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6dcd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulad\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\kulad\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# %%\n",
    "dataset = pd.read_csv('face.csv')\n",
    "dataset\n",
    "\n",
    "# %%\n",
    "mean = np.mean(dataset.iloc[:, :-1], axis=0)\n",
    "\n",
    "cov_matrix = dataset.iloc[:, :-1].cov()\n",
    "\n",
    "# %%\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues in descending order\n",
    "indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues_sorted = eigenvalues[indices]\n",
    "eigenvectors_sorted = eigenvectors[:, indices]\n",
    "\n",
    "total_variance = np.sum(eigenvalues_sorted)\n",
    "\n",
    "variance_threshold = 0.95\n",
    "cumulative_variance = np.cumsum(eigenvalues_sorted) / total_variance\n",
    "k = np.argmax(cumulative_variance >= variance_threshold) + 1  # Add 1 because indexing starts from 0\n",
    "\n",
    "selected_eigenvectors = eigenvectors_sorted[:, :k]\n",
    "selected_eigenvalues = eigenvalues_sorted[:k]\n",
    "\n",
    "data_reduced = np.dot(dataset.iloc[:, :-1]-mean, selected_eigenvectors)\n",
    "data_reduced.shape\n",
    "\n",
    "\n",
    "# %%\n",
    "test = data_reduced[390:400]\n",
    "test = np.concatenate([test, data_reduced[790:800]])\n",
    "\n",
    "train = data_reduced[0:390]\n",
    "train = np.concatenate([train, data_reduced[400:790]])\n",
    "\n",
    "# %%\n",
    "means = [np.mean(train[0:390], axis=0), np.mean(train[390:], axis=0)]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    min_dist = float('inf')\n",
    "    prediction = -1\n",
    "\n",
    "    for j in range(2):\n",
    "        dist = np.linalg.norm(test[i] - means[j])\n",
    "\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            prediction = j\n",
    "\n",
    "    predictions.append(prediction)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if i<10 and predictions[i] == 0:\n",
    "        correct += 1\n",
    "    elif i>10 and predictions[i] == 1:\n",
    "        correct += 1\n",
    "    else:\n",
    "        correct -= 1\n",
    "\n",
    "print('Accuracy : ', correct/test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6c1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulad\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\kulad\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from 'face.csv'\n",
    "data = pd.read_csv('face.csv')\n",
    "\n",
    "# Calculate the mean of the dataset columns except the last one\n",
    "X=data.iloc[:,:-1]\n",
    "feature_means = np.mean(X, axis=0)\n",
    "\n",
    "# Calculate the covariance matrix of the dataset columns except the last one\n",
    "covariance_matrix = X.cov()\n",
    "\n",
    "# Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# Sort eigenvalues in descending order\n",
    "eigenvalue_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[eigenvalue_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, eigenvalue_indices]\n",
    "\n",
    "# Calculate the total variance\n",
    "total_variance = np.sum(sorted_eigenvalues)\n",
    "\n",
    "# Set a threshold for the cumulative variance to retain\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Calculate cumulative variance and determine the number of principal components to retain\n",
    "cumulative_variance = np.cumsum(sorted_eigenvalues) / total_variance\n",
    "num_components_to_retain = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "\n",
    "# Select the top 'num_components_to_retain' eigenvectors\n",
    "selected_eigenvectors = sorted_eigenvectors[:, :num_components_to_retain]\n",
    "selected_eigenvalues = sorted_eigenvalues[:num_components_to_retain]\n",
    "\n",
    "# Reduce the data using the selected eigenvectors and mean\n",
    "reduced_data = np.dot(face_dataset.iloc[:, :-1] - feature_means, selected_eigenvectors)\n",
    "reduced_data_shape = reduced_data.shape\n",
    "\n",
    "# Split the data into test and training sets\n",
    "test_data = np.concatenate([reduced_data[390:400], reduced_data[790:800]])\n",
    "train_data = np.concatenate([reduced_data[0:390], reduced_data[400:790]])\n",
    "\n",
    "# Calculate the means for the two classes in the training data\n",
    "class_means = [np.mean(train_data[0:390], axis=0), np.mean(train_data[390:], axis=0)]\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "predictions = []\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    min_distance = float('inf')\n",
    "    predicted_class = -1\n",
    "\n",
    "    for j in range(2):\n",
    "        distance = np.linalg.norm(test_data[i] - class_means[j])\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            predicted_class = j\n",
    "\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if i < 10 and predictions[i] == 0:\n",
    "        correct += 1\n",
    "    elif i >= 10 and predictions[i] == 1:\n",
    "        correct += 1\n",
    "    else:\n",
    "        correct -= 1\n",
    "\n",
    "accuracy = correct / test_data.shape[0]\n",
    "\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3214b8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eigen_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 89>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m eigenvectors \u001b[38;5;241m=\u001b[39m eigenvectors[:, sorted_indices[:d]]\n\u001b[0;32m     87\u001b[0m eigenvalues \u001b[38;5;241m=\u001b[39m eigenvalues[:d]\n\u001b[1;32m---> 89\u001b[0m pca_result\u001b[38;5;241m=\u001b[39m\u001b[43meigen_vectors\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Transform data using PCA\u001b[39;00m\n\u001b[0;32m     92\u001b[0m train_features_pca \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(train_features, pca_result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eigen_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate covariance matrix\n",
    "def calculate_covariance_matrix(data_matrix):\n",
    "    mean_vector = np.mean(data_matrix, axis=0)\n",
    "    data_matrix_centered = data_matrix - mean_vector\n",
    "    return np.dot(data_matrix_centered.T, data_matrix_centered) / (data_matrix_centered.shape[0] - 1)\n",
    "\n",
    "# Perform Principal Component Analysis\n",
    "def perform_pca(data_matrix, d=0):\n",
    "    mean_vector = np.mean(data_matrix, axis=0)\n",
    "    covariance_matrix = calculate_covariance_matrix(data_matrix)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    if d > 0 and d < 1:\n",
    "        total_variance = np.sum(eigenvalues)\n",
    "        selected_eigenvalues = []\n",
    "        cumulative_variance = 0\n",
    "        i = 0\n",
    "        while cumulative_variance < d * total_variance:\n",
    "            cumulative_variance += eigenvalues[i]\n",
    "            selected_eigenvalues.append(eigenvalues[i])\n",
    "            i += 1\n",
    "        selected_eigenvalues = np.array(selected_eigenvalues)\n",
    "        d = i\n",
    "    eigenvectors = eigenvectors[:, sorted_indices[:d]]\n",
    "    eigenvalues = eigenvalues[:d]\n",
    "    return eigenvectors\n",
    "\n",
    "# Perform Minimum Distance Classifier\n",
    "def min_distance_classifier(train_data, train_labels, test_data):\n",
    "    class_means = {}\n",
    "    for label in np.unique(train_labels):\n",
    "        class_means[label] = np.mean(train_data[train_labels == label], axis=0)\n",
    "    \n",
    "    predictions = []\n",
    "    for sample in test_data:\n",
    "        min_distance = float('inf')\n",
    "        predicted_class = None\n",
    "        for label, mean in class_means.items():\n",
    "            distance = np.sqrt(np.sum((sample - mean) ** 2))\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                predicted_class = label\n",
    "        predictions.append(predicted_class)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('face.csv')\n",
    "\n",
    "# Separate data into training and testing sets\n",
    "unique_classes = data['target'].unique()\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for class_label in unique_classes:\n",
    "    train_data = pd.concat([train_data, data[data['target'] == class_label].iloc[2:]], ignore_index=True)\n",
    "    test_data = pd.concat([test_data, data[data['target'] == class_label].iloc[:2]], ignore_index=True)\n",
    "\n",
    "train_features = train_data.drop(['target'], axis=1).values\n",
    "train_labels = train_data['target'].values\n",
    "test_features = test_data.drop(['target'], axis=1).values\n",
    "test_labels = test_data['target'].values\n",
    "\n",
    "# Perform PCA\n",
    "data_matrix=train_features\n",
    "d=0\n",
    "mean_vector = np.mean(data_matrix, axis=0)\n",
    "covariance_matrix = calculate_covariance_matrix(data_matrix)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "if d > 0 and d < 1:\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "    selected_eigenvalues = []\n",
    "    cumulative_variance = 0\n",
    "    i = 0\n",
    "    while cumulative_variance < d * total_variance:\n",
    "        cumulative_variance += eigenvalues[i]\n",
    "        selected_eigenvalues.append(eigenvalues[i])\n",
    "        i += 1\n",
    "    selected_eigenvalues = np.array(selected_eigenvalues)\n",
    "    d = i\n",
    "eigenvectors = eigenvectors[:, sorted_indices[:d]]\n",
    "eigenvalues = eigenvalues[:d]\n",
    "\n",
    "pca_result=eigenvectors\n",
    "\n",
    "# Transform data using PCA\n",
    "train_features_pca = np.dot(train_features, pca_result)\n",
    "test_features_pca = np.dot(test_features, pca_result)\n",
    "\n",
    "# Perform Minimum Distance Classifier on the PCA-transformed data\n",
    "predicted_labels = min_distance_classifier(train_features_pca, train_labels, test_features_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(predicted, true):\n",
    "    return np.sum(predicted == true) / len(true)\n",
    "\n",
    "accuracy_value = calculate_accuracy(predicted_labels, test_labels)\n",
    "accuracy_percentage = accuracy_value * 100\n",
    "\n",
    "print(\"Accuracy: \", accuracy_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ed3739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.85\n",
      "Accuracy percentage:  85.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate covariance matrix\n",
    "def calculate_covariance_matrix(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X = X - mean\n",
    "    return np.dot(X.T, X) / (X.shape[0] - 1)\n",
    "\n",
    "# Perform Principal Component Analysis\n",
    "def perform_pca(X, d=0):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    cov_matrix = calculate_covariance_matrix(X)\n",
    "    eig_val, eig_vec = np.linalg.eig(cov_matrix)\n",
    "    indices = np.argsort(eig_val)[::-1]\n",
    "    eig_val = eig_val[indices]\n",
    "    if d > 0 and d < 1:\n",
    "        total_var = np.sum(eig_val)\n",
    "        selected_eig_val = []\n",
    "        cum_var = 0\n",
    "        i = 0\n",
    "        while cum_var < d * total_var:\n",
    "            cum_var += eig_val[i]\n",
    "            selected_eig_val.append(eig_val[i])\n",
    "            i += 1\n",
    "        selected_eig_val = np.array(selected_eig_val)\n",
    "        d = i\n",
    "    eig_vec = eig_vec[:, indices[:d]]\n",
    "    eig_val = eig_val[:d]\n",
    "    return eig_vec\n",
    "\n",
    "\n",
    "# Perform Minimum Distance Classifier\n",
    "def min_distance_classifier(X_train, y_train, X_test):\n",
    "    class_means = {}\n",
    "    for label in np.unique(y_train):\n",
    "        class_means[label] = np.mean(X_train[y_train == label], axis=0)\n",
    "    \n",
    "    predictions = []\n",
    "    for sample in X_test:\n",
    "        min_distance = float('inf')\n",
    "        predicted_class = None\n",
    "        for label, mean in class_means.items():\n",
    "            distance = np.sqrt(np.sum((sample - mean) ** 2))\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                predicted_class = label\n",
    "        predictions.append(predicted_class)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('face.csv')\n",
    "\n",
    "# Separate data into training and testing sets\n",
    "classes = data['target'].unique()\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for i in classes:\n",
    "    train_data = pd.concat([train_data, data[data['target'] == i].iloc[2:]], ignore_index=True)\n",
    "    test_data = pd.concat([test_data, data[data['target'] == i].iloc[:2]], ignore_index=True)\n",
    "\n",
    "X_train = train_data.drop(['target'], axis=1).values\n",
    "y_train = train_data['target'].values\n",
    "X_test = test_data.drop(['target'], axis=1).values\n",
    "y_test = test_data['target'].values\n",
    "\n",
    "# Perform PCA\n",
    "pca_result = perform_pca(X_train, d=0.95)\n",
    "\n",
    "# Transform data using PCA\n",
    "X_train_pca = np.dot(X_train, pca_result)\n",
    "X_test_pca = np.dot(X_test, pca_result)\n",
    "\n",
    "# Perform Minimum Distance Classifier on the PCA-transformed data\n",
    "y_predicted = min_distance_classifier(X_train_pca, y_train, X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(predicted, true):\n",
    "    return np.sum(predicted == true) / len(true)\n",
    "\n",
    "accuracy_value = calculate_accuracy(y_predicted, y_test)\n",
    "accuracy_percentage = accuracy_value * 100\n",
    "\n",
    "print(\"Accuracy: \", accuracy_value)\n",
    "print(\"Accuracy percentage: \", accuracy_percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69578f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
